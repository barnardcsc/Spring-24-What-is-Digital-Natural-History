---
title: "Digital Natural History Workshop"
output: html_notebook
---

### Overview

This workshop and this notebook are structured in three portions. 

The first "show-and-tell" portion briefly addresses the question of "what is natural history" and also delves into the history of natural history, culminating in the ongoing transition to a natural history that still exists and has grown to include Digital Natural History. 
The second portion is more interactive, also using links to on-line resources along with chunks of code to demonstrate how to access and filter from open APIs. There are many huge and growing data repositories of biodiversity data. This is cool for enthusiastic amateurs, students and professionals, whether in biology, data science or computing.  

There are third and fourth portions for doing some evolutionary and ecological analyses used in evolutionary biology and in investigating community ecology (the science of coexisting biodiversity). We may not have time for either of these, but there pretty basic and might interest some participants later.  

### 1. Show-and-Tell: The History of Natural History

I'd like to first introduce an on-line text digitization project, The Biodiversity Heritage Library (BHL): https://www.biodiversitylibrary.org  BHL enables access to so many historical texts, including one of the earliest (1526) about natural history of the central and southern Americas. This is clearly an inherently colonialist project at the behest of Gonzalo Fernández de Oviedo y Valdés, a soldier and botanist from Spain who wrote multiple volumes about his first-hand observations. He often wrote about animals and plants. https://www.biodiversitylibrary.org/bibliography/156633 

Also in the 16th century is the origin of European universities, like Bologna or Padua, articulating ideals of academic freedom, and scholarship in service to the greater good, training medical scholars who required botanical gardens, somethign that traces to 1545 at the University of Padua, now a UNESCO World Heritage Site https://whc.unesco.org/en/list/824/

Beyond building libraries and filling them with texts, and planting gardens, 16th century Italian scholars originated the collecting, pressing and preserving of the plants themselves, bound into books called herbaria. Botanists often point to Luca Ghini
https://herbariumworld.wordpress.com/2018/03/05/at-the-beginning-luca-ghini/ 

Now heading to Germany, and the 16th century, Johannes Thal is credited for creating one of the earliest regional catalogues of European plants (1588). Such books are still prepared, published and consulted today. Such a book is referred to as a "flora" if about plants and a "fauna" if about animals.
https://www.biodiversitylibrary.org/item/223341#page/7/mode/1up 

I want to say that on the animal side, things don't go back quite as far. This 
World Heritage Site - the world's oldest zoo - Vienna, Schönbrunn Zoo
https://www.zoovienna.at/en/zoo-and-visitors/welcome-worlds-oldest-zoo/ 

Exceptional women sometimes worked as insiders in this world, like the outstanding 17th century artist and book entrepreneur Maria Sibylla Merian, beginning her life in Germany and then emigrating to the Netherlands and living for several years in the tropics, in colonial Dutch Surinam. 
https://nmwa.org/art/artists/maria-sibylla-merian/

We must discuss the mid-18th century career of Sweden's Carl Linnaeus 
https://www.linnean.org/learning
https://www.linnean.org/learning/who-was-linnaeus/linnaeus-and-race-easy-read 

New York's Jane Colden was a contemporary and correspondent with Linnaeus, self-educated and homeschooled in botany and Latin while living with her father Cadwalleder Colden, a politician and colonial governor of New York 
https://www.osgf.org/pioneers-of-natural-history-blogs-posts/2022/11/28/historical-context-for-the-botanic-manuscript-of-jane-colden-1724-1760-americas-first-woman-botanist  

Also in the 18th century was Jamaican-born Mary Seacole, active in British military nursing and herbalism
https://www.maryseacoletrust.org.uk/learn-about-mary/ 

And right here in New York City was David Hosack, a contemporary of both Mary Seacole and Alexander Hamilton, a physician and botanist who was pivotal in the founding of Columbia's Physicians & Surgeons College and also the founder and champion of Elgin Botanical Gardens, sited on land once owned by Columbia and now where Rockefeller Center stands 
https://wwnorton.com/books/9781631496011 

Then we fast forward to 135 years ago in 1889, when Barnard was founded, and a year later the founding of the New York Botanical Garden, led by the botanical power couple of New York City botany, professor Nathanial Britton and his spouse, Cuban-born Elizabeth Knight Britton Both were very friendly with Barnard's own Dr. Emily Gregory, the first professor appointed as a Barnard-specific professor. 

https://www.nybg.org/blogs/science-talk/2013/11/elizabeth-britton-real-life-inspiration-for-a-fictional-heroine/ 

The Brittons and their friends and colleagues helped to make sure that both NYBG and Barnard have their own herbaria, with the NYBG a major leader in converting their material herbarium into digital formats, something that I would like to use with Barnard's own small and important herbarium. 

https://sweetgum.nybg.org/science/vh/

After the 1893 World Columbia Exhibition in Chicago's Field Museum, including a large herbarium, and one that was way ahead of others when it started the Berlin Negatives project to photograph type specimens and send them to Europe. 

https://www.fieldmuseum.org/vplants-a-virtual-herbarium-of-the-chicago-region

https://www.fieldmuseum.org/collection/berlin-negatives 

The 1990s and the dawn of digitizing efforts, and an early project digitally "repatriating" of type specimens of plants from Brazil 
https://www.kew.org/science/our-science/projects/reflora 

Digital Herbaria - now aggregated by i-DigBio
https://www.idigbio.org/portal/search 

I'll close this first section by noting that I've tried that there is some diversity among those who contributed to natural history and biodiversity over the years, but like most things it is unequivocally white and patriarchal  see this article
https://doi.org/10.1002/ppp3.10478

Moreover, there are real issues in bioprospecting, for chemical or pharmaceutical industries , can cross over into unsustainable, unethical, unjust or even criminal activities. Sometimes called biopiracy, there have been for decades  international efforts to negotiate treaties and improve protocols to be more equitable and fair.
https://www.cbd.int/abs

And when it comes to the data-biodiversity nexus, there is a growing movement known as Indigenous Data Sovereignty, one portion of a large movement to ensure proper balance of privacy with open access to data
https://www.stateofopendata.od4d.net/chapters/issues/indigenous-data.html

### 2. Becoming A Digital Naturalist: Tools To Create and Use Biodiversity Data

Now the second portion of the workshop, aiming to be more interactive, and will start with I-Naturalist, and then proceed to I-DigBio and GBIF, the Global Biodiversity Information Facility. I suspect that's because you loved the interactive searching of the NYBG digital herbarium. 

So this part is designed to work as an on-line resource to use on a computer, in tandem with an cell-phone based app. If you don't already have this downloaded to your cell-phone, I strongly endorse doing so, and if you have an account already, you can go to review your so-called "life list" and you can also search for me and my observations and other profile information. 
https://www.inaturalist.org/observations


```{r}
# on-line resource https://www.inaturalist.org/observations & pre-downloaded Google drive data file

install.packages("googlesheets4") #import dataframes; REQUIRES interaction for accessing account
library(googlesheets4) #interactive import - must read in Console how to pre-authorize account
HilaryAll<-read_sheet("https://docs.google.com/spreadsheets/d/1e4C0rB1rdBvFNVFoXb_n8rftQ6qVKT1lxXhDBTTuiyg/edit#gid=174974365")
  
library(dplyr)
HilaryAllSlim<-HilaryAll  %>% select(c("latitude", "longitude", "scientific_name","common_name"))
HilaryAllSlim

```

The second and third resources to test-drive are GBIF and I-DigBio. 

GBIF stands for Global Biodiversity Information Facility
https://www.gbif.org/ 

I-DigBio includes 
https://www.idigbio.org/


For GBIF, I  have already mentioned and demonstrated how that some data in GBIF comes from I-Naturalist, provided it passes muster to achieve "research grade" criteria. 

The I-DigBio aggregator and portal are for collections of preserved specimens, such as museums and herbaria, also aggregated within GBIF.  


```{r}
install.packages("taxize") #package for working with taxonomic data, taps into Global Names Resolver
install.packages("spocc") #package connects to databases with open API; filtering & selecting occurrences 
# DEVELOPER OF SPOCC https://github.com/ropensci/spocc
# DOCUMENTATION OF SPOCC https://cloud.r-project.org/web/packages/spocc/spocc.pdf
# TUTORIAL WITH SPOCC https://rspatialdata.github.io/species_occurrence.html#Introduction
# NOTE SPOCC has mostly replaced tools for individual data bases
# OUT-OF-DATE BUT EXCELLENT DISCUSSION https://cran.r-project.org/web/packages/CoordinateCleaner/vignettes/Cleaning_GBIF_data_with_CoordinateCleaner.html

library(spocc)
library(rgbif)
library(rinat)
library(ridigbio)

# Can we search for records related to a park right nearby? I've downloaded the geographic information for Sakura Park, which is just north of Riverside Church. 

Sakura1<-occ(from = "gbif",
geom = 'POLYGON((-73.96215820728446 40.81239369455827, -73.96136732339409 40.81347885128151, -73.96196434587753 40.813730180464894, -73.9619988861022 40.81374472137774, -73.96278976166968 40.81265955946826, -73.96215820728446 40.81239369455827))', 
limit = 50
)

Sakura2<-occ(from = "ebird",
geom = 'POLYGON((-73.96215820728446 40.81239369455827, -73.96136732339409 40.81347885128151, -73.96196434587753 40.813730180464894, -73.9619988861022 40.81374472137774, -73.96278976166968 40.81265955946826, -73.96215820728446 40.81239369455827))', 
limit = 50
)


occ2df(Sakura1)

occ2df(Sakura2)

# We could also look for a favorite plant that some of you may know from Barnard's Ross Greenhouse, the giant corpse flower or titan arum, native to Indonesia and increasingly popular in greenhouse conservatory collections

TitanArum<-occ(query = "Amorphophallus titanum", from = "gbif", limit = 100)
               
occ2df(TitanArum)

```


Tapping into these requires three additional things, and I'll discuss only the third of these today because it's the only one that's distinctively related to natural history. 
1. Spatial data experience and mapping experiences (GIS, etc)
2. Data cleaning 
3. Systematics - how are organisms named, classified and related. 

Interestingly, these have become well-discussed because many racist and colonial legacies are embedded in these names, as I touched on earlier when highlighting Linnaeus as pivotal in the history of this field of expertise. 

And I don't want to dismiss the need for reform, but it completely mandatory in 2024 to use and to understand how the scientific names of diverse organisms are standardized. This is fundamental data science, in the realm of meta-data, or the data that we use to organize our data. .

it's nice to know about Plants of the World On-line resource at the Kew Gardens in Great Britain. Also important is something called the Global Names Resolver and, 
https://powo.science.kew.org/ 
https://resolver.globalnames.org/about

Four fundamental activities/questions?
1. Assuming all lists of plants are interesting, let's make some plant lists
2. Do we need to know the scientific names for plants? Yes. I'll show how. 
3. Once we have scientific names of organisms, can we validate and classify them? How?
4. What types of questions we can address with plant lists?

Here's the first list, a tomato soup recipe:
olive oil
yellow onion
garlic
tomato
basil
sugar
black pepper
salt

Here's the second list, of the ingredients in Oreo cookies:  
wheat
sugar
palm oil
soybean oil
canola oil
cocoa
corn syrup

We could look up the plants in these foods by simply Googling, or by using Wikipedia or tools like the Encyclopedia of Life
# https://en.wikipedia.org/wiki/Olive
# https://eol.org/pages/579181 

Plants of the World Online (POWO), is a free and accessible data-base, good for lookups
https://powo.science.kew.org/ 

```{r}
# https://en.wikipedia.org/wiki/Olive
# https://eol.org/pages/579181

# https://powo.science.kew.org/ is a free and accessible data-base, good for lookups

library(kewr)
olive<-search_powo("olives")
olive
```


```{r}
install.packages("vegan") #vegetation analysis software - analysis of high-dimension data
install.packages("ape")   #tools for phylogenetic analysis and evolution research


install.packages("tidyr") #for data filtering, selecting, re-shaping
```


```{r}
# Once again, I am going to tap into some pre-prepared data sets 
library(tidyr)
library(googlesheets4)

# We have probably already loaded ("activated") these software tools, but not a bad idea to remind ourselves that we are using them and re-load
library(taxize)
library(vegan)
library(ape)

# And the new package that we downloaded above, to allow us to figure out and draw a family tree or geneology for our list of plants, referred to by biology experts as a phylogeny

```

Let's say you could get species names for our soup and cookie recipes by Googling. 

Tomato soup recipe:
Olea europaea L.
Allium cepa L.
Allium sativum L.
Solanum lycopersicon L.
Ocimum basilicum L.
Saccharum officinarum L.
Beta vulgaris L.
Piper nigrum L.

Oreo ingredients: 
Triticum aestivum L. 
Saccharum officinarum L.
Beta vulgaris L.
Elaeis guineensis Jacq.
Glycine max (L.) Merr.
Brassica napa L.
Theobroma cacao L.
Zea mays L.

How would you know the information is correct? You can do something called "resolving" the names, using two packages already developed and widely used, in R. One is called APE for Analysis of Phylogeny and Evolution. The other called TAXIZE is for taxonomy.  

```{r}
library(ape)
library(taxize)

# Global Names Resolver, and older source; this is in transition at the time of this workshop
# Global Names Verifier,  available at this URL: https://verifier.globalnames.org/
# Despite the availability of the second, newer and better resource, many R packages still use the first and older oen, and it works quite well to help validate species names

soupR<-gnr_resolve(sci = c("Olea europaea L.",
"Allium cepa L.",
"Allium sativum L.",
"Solanum lycopersicon L.",
"Ocimum basilicum L.",
"Saccharum officinarum L.",
"Beta vulgaris L.",
"Piper nigrum L."
), data_source_ids = 11, canonical = F)


cookieR<-gnr_resolve(sci = c("Triticum aestivum L.", 
"Saccharum officinarum L.",
"Beta vulgaris L.",
"Elaeis guineensis Jacq.", 
"Glycine max (L.) Merr.",
"Brassica napa L.",
"Theobroma cacao L.",
"Zea mays L."
),
data_source_ids = 11, canonical = F)

# or line 251 could be swapped with the line below
# best_match_only=T)
# data source eleven is GBIF, and among the best and most definitive sources; more on this below


```


```{r}
# This code chunk demontrates GBIF instead of GNR as a tools to validate names for lists of organisms 

# https://www.gbif.org/search 

library(rgbif)

name_data1 <- data.frame(species = soupR$matched_name)
name_data2 <- data.frame(species = cookieR$matched_name)

# Within GBIF, there is a "backbone" and any list can be attached (like a rib) to that backbone:

SoupHigher<-name_backbone_checklist(name_data1)
CookieHigher<-name_backbone_checklist(name_data2)

```

```{r}
#SELECTING JUST THE NEEDED VARIABLES FROM THE ABOVE OUTPUT
library(dplyr)
name_for_phylo1<-SoupHigher  %>% select(c("canonicalName", "genus", "family","order"))
name_for_phylo1


name_for_phylo2<-CookieHigher  %>% select(c("canonicalName", "genus", "family","order"))
name_for_phylo2


```


## 3. The Tree of Life and Organisms' Evolutionary Relationships

Kew Gardens has a Tree of Life Project for plants
https://treeoflife.kew.org/

Another rather cool visualizer of evolutionary relationships is OneZoom
https://www.onezoom.org/ 

I am going to show you something I teach in my class, again for plants, to take any list of plants and figure out evolutionary relationships, a package called VPhylomaker2. 
https://github.com/jinyizju/V.PhyloMaker2

```{r}
# URL for V.PhyloMaker2 https://github.com/jinyizju/V.PhyloMaker2
# DOI for publication VPhyloMaker2: An updated and enlarged R package 

library(devtools)
devtools::install_github("jinyizju/V.PhyloMaker2") #package for "phylogenizing" lists of plants

library(V.PhyloMaker2)

# For our soup list

tree.15 <- phylo.maker(sp.list = name_for_phylo1,  tree = GBOTB.extended.WP,  nodes = nodes.info.1.WP, scenarios="S3")
write.tree(tree.15$scenario.3, "Figure.15.tre")
plot(tree.15$scenario.3, type = "phylogram")

#https://rdrr.io/cran/ape/f/inst/doc/DrawingPhylogenies.pdf

```

```{r}
# For our cookie list

tree.15 <- phylo.maker(sp.list = name_for_phylo2,  tree = GBOTB.extended.WP,  nodes = nodes.info.1.WP, scenarios="S3")
write.tree(tree.15$scenario.3, "Figure.15.tre")
plot(tree.15$scenario.3, type = "phylogram")

```




```{r}
library(googlesheets4) #Interactive - may need to give permission
SoupList<-read_sheet("https://docs.google.com/spreadsheets/d/1-iIMokvd740AUoorrOrB5JTUclbBQjqhctt3SXMBLoI/edit?usp=sharing")

name_data <- data.frame(species = SoupList$Latin_Name)

SoupListHigher3<-name_backbone_checklist(name_data)

#SELECTING JUST THE NEEDED VARIABLES FROM THE ABOVE OUTPUT
library(dplyr)
name_for_phylo3<-SoupListHigher3  %>% select(c("canonicalName", "genus", "family","order"))

recipe_ingredients<-SoupList%>% select(c("Latin_Name", "Recipe_Name", "Recipe_Type"))

SoupListAnalyze<-cbind(name_for_phylo3, recipe_ingredients)

```


```{r}
# Now we are looking at many different recipes, wondering about whether clusters of ingredients always co-exist, or if there are things that never co-exist. For example, you rarely put sugar in soup but almost always put it in cookies; and you might never put chocolate in soup. This is similar to thinking about how different types of trees co-exist. In California you will see Redwoods and Douglas Firs together, and you can find Douglas fir but not Redwoods in New York City. 

library(vegan)


# To analyze our data, we need to reshape it to a list of recipes as our cases, and many many variables which together make up the universe of possible recipe ingredients and whether or not those ingredients are used in each specific recipe. This is similar to looking at many different wilderness areas spread across many regions differing in climate, looking at which trees are found (or not found) in each regions. 

library(reshape2)

SoupListAnalyzeM1 <- melt(SoupListAnalyze, id.vars=c("Recipe_Name","canonicalName"))

Soup_sppAbun1 <- dcast(SoupListAnalyzeM1, Recipe_Name~canonicalName,value.var= 'value')

Soup_sppAbunVEGAN<-select(Soup_sppAbun1, -Recipe_Name)

# Any attempt to classify the recipes will try to figure out if there are some that cluster together because of similarity of ingredients, and others that have more exotic ingredient lists. 

# getting Jaccard (a similarity metric)
J.dist<-vegdist(Soup_sppAbunVEGAN, method = "jaccard", binary = T)
J.dist

#getting a dissimilarity metric, specifically a distance metric
bray.dist<-vegdist(Soup_sppAbunVEGAN, method = "bray")
bray.dist

# Plant ecologists have long done ordinations, and here is a quick example using something using  non-metric multidimensional scale

ord<-metaMDS(Soup_sppAbunVEGAN)
plot(ord)

```

```{r}
# To make that plot prettier, we want to be able to look at which recipes as which, so super-briefly I will highlight which are soups and three that are not soups at all - there are two cookies in this list of recipes!

data.scores = as.data.frame(scores(ord)$sites)

plotSoup<-cbind(Soup_sppAbun1, data.scores)

plotSoup<-mutate(plotSoup, Recipe_Type = ifelse(Recipe_Name == "Oreo"| Recipe_Name == "Peanut butter cookie", "Cookie","Soup"))

library(ggplot2)

ggplot(
  data = plotSoup,
  mapping = aes(x = NMDS1, y = NMDS2, color = Recipe_Type
                )
) +
  geom_point(size = 2, alpha = 0.5)
  
```





